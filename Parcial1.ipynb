{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as optimize\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import contractions\n",
    "import re, string, unicodedata\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv(\"./data/Regresión_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.isnull().sum() / datos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.isna().sum() / datos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos[\"dolor_NRS\"].value_counts()/datos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos[\"Duracion_KTAS_Min\"] = datos[\"Duracion_KTAS_Min\"].str.replace(',', '.').astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat map\n",
    "plt.figure(figsize=(12, 10))\n",
    "cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(\n",
    "    datos[numericas].corr(),\n",
    "    cmap=cmap,\n",
    "    vmin=-1, vmax=1,\n",
    "    annot=True\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos[\"Sexo_stan\"] = datos[\"Sexo\"].apply(lambda x: 0 if x == 2 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan los registros totalmente duplicados\n",
    "datos = datos.dropna(subset=[\"Duracion_Estancia_Min\"]+candidatas)\n",
    "datos[[\"Duracion_Estancia_Min\"]+candidatas].isnull().sum() / datos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.loc[datos.duplicated(subset=candidatas, keep=False)][[\"Duracion_Estancia_Min\"]+candidatas].head(10)\n",
    "duplicated_rows = datos.loc[datos.duplicated(subset=candidatas, keep=False)].shape[0]\n",
    "duplicated_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicates: {(duplicated_rows/total_rows)*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.loc[datos.duplicated(subset=candidatas+[\"Duracion_Estancia_Min\"], keep=False)].tail(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows = datos.loc[datos.duplicated(subset=candidatas+[\"Duracion_Estancia_Min\"], keep=False)].shape[0]\n",
    "duplicated_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.drop_duplicates(subset=candidatas, inplace=True)\n",
    "datos.drop_duplicates(subset=candidatas+[\"Duracion_Estancia_Min\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGRESION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(datos_recorte[candidatas], datos_recorte[\"Duracion_Estancia_Min\"], test_size=0.3, random_state=1)\n",
    "X_train.shape, y_train.shape\n",
    "X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()\n",
    "regression.fit(X_train, y_train)\n",
    "pd.DataFrame({\"columns\": candidatas, \"coef\": regression.coef_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, len(candidatas), sharey=True, figsize=(20, 5), layout=\"constrained\")\n",
    "\n",
    "for i in range(len(candidatas)):\n",
    "    col = candidatas[i]\n",
    "    x = X_train[col]\n",
    "    m = regression.coef_[i]\n",
    "    b = regression.intercept_\n",
    "\n",
    "    axs[i].plot(x, y_train, \"o\", alpha=0.1)\n",
    "    axs[i].plot(x, x * m + b)\n",
    "    axs[i].set_title(col)\n",
    "print(\"Train:\", np.sqrt(mean_squared_error(y_train, regression.predict(X_train))))\n",
    "print(\"Test:\", np.sqrt(mean_squared_error(y_test, regression.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20,10))\n",
    "ax = sns.boxplot(data=datos_cols_selec, orient=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "\n",
    "\n",
    "datos_prep_norm = datos_cols_selec.copy()\n",
    "datos_prep_norm[name_cols] = mms.fit_transform(datos_cols_selec[name_cols])\n",
    "datos_prep_norm=datos_prep_norm[name_cols]\n",
    "saved_cols = datos_prep_norm.columns\n",
    "\n",
    "datos_prep_norm = pd.DataFrame(datos_prep_norm, columns =saved_cols)\n",
    "print(datos_prep_norm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distortion(data,\n",
    "                    k_min=1, \n",
    "                    k_max=11,\n",
    "                    ylabel = 'Distortion',\n",
    "                    xlabel = 'Number of clusters',\n",
    "                    title = 'Distortion Plot'):\n",
    "    distortions = []\n",
    "    for i in range(k_min, k_max):\n",
    "        km = KMeans(n_clusters=i,\n",
    "                 init='k-means++',\n",
    "                 n_init=10,\n",
    "                 max_iter=300,\n",
    "                 random_state=0)\n",
    "        km.fit(data)\n",
    "        distortions.append(km.inertia_)\n",
    "    plt.plot(range(k_min,k_max), distortions, marker='o')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_clusters=2\n",
    "kmeans = KMeans(n_clusters=N_clusters, random_state=0) \n",
    "kmeans = kmeans.fit(datos_prep_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "datos_prep_norm['Cluster'] = labels\n",
    "\n",
    "cluster_distrib = datos_prep_norm['Cluster'].value_counts()\n",
    "\n",
    "fig=plt.figure(figsize=(12,8))\n",
    "sns.barplot(x=cluster_distrib.index, y=cluster_distrib.values, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=datos_prep_norm, hue=\"Cluster\", palette=\"Dark2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouette(data, \n",
    "                    labels,\n",
    "                   ylabel = 'Grupos',\n",
    "                   xlabel = \"Coeficiente de silueta\",\n",
    "                   title = 'Gráfica de silueta'):\n",
    "    cluster_labels = np.unique(labels)\n",
    "    print(cluster_labels)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = silhouette_samples(data,\n",
    "                                        labels,\n",
    "                                        metric='euclidean')\n",
    "    y_ax_lower, y_ax_upper = 0, 0\n",
    "    yticks = []\n",
    "    for i, c in enumerate(cluster_labels):\n",
    "        c_silhouette_vals = silhouette_vals[labels == c]\n",
    "        c_silhouette_vals.sort()\n",
    "        y_ax_upper += len(c_silhouette_vals)\n",
    "        color = cm.jet(float(i) / n_clusters)\n",
    "        plt.barh(range(y_ax_lower, y_ax_upper),\n",
    "                        c_silhouette_vals,\n",
    "                        height=1.0,\n",
    "                        edgecolor='none',\n",
    "                        color=color)\n",
    "        yticks.append((y_ax_lower + y_ax_upper) / 2.)\n",
    "        y_ax_lower += len(c_silhouette_vals)\n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    plt.axvline(silhouette_avg,\n",
    "                color=\"red\",\n",
    "                linestyle=\"--\")\n",
    "    plt.yticks(yticks, cluster_labels+1)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arboles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Ahora definimos la función que nos va a permitir construir nuestra clase.\n",
    "def label_popularity (row):\n",
    "    if row['popularity'] > 33 :\n",
    "        return 1\n",
    "    return 0\n",
    "df_tracks_t['popularity_label']=df_tracks_t.apply (lambda row: label_popularity(row), axis=1) "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
